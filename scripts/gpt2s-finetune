#!/bin/bash
set -e
PORT=$RANDOM
PORT=$((PORT + 1000))
WANDB_ENTITY=eleutherai uv run torchrun --master_port $PORT --nproc_per_node gpu -m sparsify \
openai-community/gpt2 --ctx_len 128 --filter_bos=True \
--transcode=True --skip_connection=True \
--batch_size=8 --expansion_factor=128 --tp=2 --k=16 \
--hookpoints h.0.mlp h.1.mlp h.2.mlp h.3.mlp h.4.mlp h.5.mlp h.6.mlp h.7.mlp h.8.mlp h.9.mlp h.10.mlp h.11.mlp \
--run_name clt-gpt2-finetune/$1 --finetune checkpoints/gpt2-sweep/$1 ${@:2} \
--lr 5e-5 --optimizer adam --lr_warmup_steps 50 \
--normalize_io=True --post_encoder_scale=True \
--loss_fn kl-fvu --kl_coeff 0.0 \
# --b1 0.9
# --coalesce_topk=concat --topk_coalesced=False --post_encoder_scale=True --normalize_io=True --cross_layer=12 \
# --loss_fn kl \
